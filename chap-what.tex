This survey serves as an introduction and detailed overview of some topics in (probability) distribution testing, an area of theoretical computer science which falls under the general umbrella of \emph{property testing}, and sits at the intersection of computational learning, statistical learning and hypothesis testing, information theory, and (depending on whom one asks) the theory of machine learning. Broadly speaking, distribution testing is concerned with the following type of questions: 
\begin{framed}
 Given a \textbf{small} number of independent data points from some blackbox random source, can we \textbf{efficiently} decide whether the distribution of the data follows some purported model (``property''), or is statistically far from doing so?
\end{framed}

Of course, there are many details to be made precise here. What type of assumptions on the data do we make -- is it discrete, continuous, univariate, high-dimensional?  What do we mean by ``efficiently'' -- the number of data points (data efficiency), the running time of our algorithms (time efficiency), both? What do we mean by ``far'' -- what notion of distance are we considering? And what type of error do we allow -- false positives (Type I), false negative (Type II)?

Some of these are left flexible, as we will see below when formally introducing the setting of distribution testing. However, the general idea is to focus on \emph{finite sample guarantees} (no qualitative limiting statements as data size grows to infinity), for a \emph{fixed error probability target} $\errprob$ controlling both Type I and Type II, and making \emph{as few assumptions as possible} under the (composite) alternative hypothesis. That is, we will answer questions of the form ``either the distribution of the data satisfies the property, or it is \emph{pretty much anything} far from that.''


Adopting a Computer Science viewpoint, we will also assume that the ``size'' of the object considered -- typically, the domain size for discrete data -- is large, which allows us to focus on the first-order dependence on this quantity. This also implies we typically consider a \emph{worst-case} (minimax) setting with respect to this quantity, making statements about the worst-case data size, or time, required to achieve our goal. This does not means the algorithms and ideas obtained do not lead to ``practical'' algorithms: rather, that people working in distribution testing are quite pessimistic and paranoid in nature, and want the guarantee that things are \emph{never} too slow before the promise that they \emph{often} are quite fast. (Moreover, as we will see later, the worst-case instances for most of our testing tasks are actually quite natural, and likely to arise in practice! Paranoia, for once, may be warranted.)

\paragraph{A note.} For simplicity, throughout this survey we will sweep under the rug many measure-theoretic subtleties, and assume probability distributions, probability density functions (pdf), and probability mass functions (pmf) exist whenever required, and are suitably well-behaved. We will also typically identify a probability distribution with its pdf or pmf, and by a slight abuse of notation use $\p$ indifferently for the distribution itself and its pdf. Most, if not all, of those subtleties can be handled by inserting the words ``Radon--Nikodym,'' ``measurable,'' and ``counting measure'' in suitable places and order.

\section{Formulation, and relation to Hypothesis Testing}
\label{sec:formulation}

In what follows, $\ab\in\N$ will be used to parametrize the domain of the probability distributions: namely, $\distribs{\ab}$ will denote the set of probability distributions over a (known) domain $\domain_\ab$.

We begin with the notion of distance we will be concerned about, the total variation distance (also known as \emph{statistical distance}):
\begin{definition}[Total variation distance]
  \label{def:tv}
  The \emph{total variation distance} between two probability distributions $\p,\q\in\distribs{\ab}$ is given by
  \[
    \totalvardist{\p}{\q} = \sup_{S\subseteq \domain_\ab} (\p(S)-\q(S))\,.
  \]
  Given a subset $\class\subseteq\distribs{\ab}$ of distributions, we further define the distance from $\p\in\distribs{\ab}$ to $\class$ as $\totalvardist{\p}{\class} \eqdef \inf_{\q\in\class} \totalvardist{\p}{\q}$, and will say that $\p$ is \emph{$\dst$-far from $\class$} if $\totalvardist{\p}{\class} > \dst$.
\end{definition}
One can check that $\dtv$ defines a metric on $\distribs{\ab}$, and takes values in $[0,1]$.\exercise{Check it!} Moreover, the total variation distance exhibits several important properties, some of which will be detailed at length in~\cref{app:distances}; we recall a crucial one below.

\begin{fact}[Data Processing Inequality]
  \label{fact:dpi}
  Suppose $X$ and $Y$ are independent random variables with distributions $\p$ and $\q$, and let $f$ be any (possibly randomized) function independent of $X,Y$. Then the probability distributions $\p_f$ and $\q_f$ of $f(X)$ and $f(Y)$ satisfy
  \[
      \totalvardist{\p_f}{\q_f} \leq \totalvardist{\p}{\q}\,.
  \]
  That is, \emph{postprocessing cannot increase the total variation distance.}
\end{fact}


Assuming that $\p,\q$ are absolutely continuous with respect to some dominating measure $\mu$,
  \begin{equation}
    \totalvardist{\p}{\q} = \frac{1}{2}\int \abs{\dv{\p}{\mu}-\dv{\q}{\mu}}\dd{\mu}
  \end{equation}
  In the discrete case where $\p,\q$ are both over $\N$ or a finite domain, this leads to
  \begin{equation}
    \label{eq:tv:l1}
    \totalvardist{\p}{\q} = \frac{1}{2}\normone{\p-\q}
  \end{equation}
  that is, ``total variation is half the $\lp[1]$ distance between pmfs.'' This turns out to be a very useful connection, since $\lp[p]$ norms are quite well-studied beasts: we get to use our arsenal of geometric inequalities --- H\"older, Cauchy--Schwarz, and monotonicity of $\lp[p]$ norms, to name a few.\smallskip

%nondecreasing in their first argument and nonincreasing in the last two
One last piece of terminology: a \emph{property}\index{property} of distributions is a predicate we are interested in (\eg ``is the probability distribution unimodal?''). By identifying the predicate with the set of objects which satisfy it, we can equivalently view a property of distributions as a \emph{subset} of probability distributions (typically, with some interesting structure). Which is what we will do: throughout, a property is just an arbitrary subset of distributions we are interested in (see~\cref{fig:propertytesting} for an illustration). With this in hand, we are ready to provide a formal definition of what a ``testing algorithm'' is.
\begin{definition}[Testing algorithm]
  \label{def:testing}
Let $\property= \bigcup_{\ab=1}^\infty \property_\ab$ and $\class= \bigcup_{\ab=1}^\infty \class_\ab$ be two properties of probability distributions, where $\property_\ab, \class_\ab\subseteq \distribs{\ab}$ for all $\ab$; and $\ns\colon\N\times(0,1]\times(0,1]\to\N$, $\tc\colon\N\times(0,1]\times(0,1]\to\N$ be two functions. A \emph{testing algorithm for \property under $\class$ with sample complexity $\ns$ and time complexity $\tc$} is a (possibly randomized) algorithm $\Algo$ which, on input $\ab\in\N,\dst \in(0,1], \errprob\in(0,1]$, and a multiset $S$ of $\ns(\ab,\dst,\errprob)$ elements of $\domain_\ab$, runs in time at most $\tc(\ab,\dst,\errprob)$ and outputs $\mathbf{b} \in\{\reject,\accept\}$ such that the following holds.
\begin{itemize}
  \item If $S$ is \iid from some $\p\in\property_\ab$, then $\probaDistrOf{S,\Algo}{\mathbf{b}=\accept} \geq 1-\errprob$;
  \item If $S$ is \iid from some $\p\in\class_\ab$ such that $\totalvardist{\p}{\property_\ab} > \dst$, then $\probaDistrOf{S,\Algo}{\mathbf{b}=\reject} \geq 1-\errprob$,
\end{itemize}
where in both cases the probability is over the draw of the \iid sample $S$ from the (unknown) $\p$, and the internal randomness of $\Algo$.
\end{definition}
\noindent The \emph{sample complexity of testing \property under $\class$} is then the minimum sample complexity $\ns(\ab,\dst,\errprob)$ achievable by a testing algorithm.\smallskip

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]\centering

\tikzset {_3eubqr20l/.code = {\pgfsetadditionalshadetransform{ \pgftransformshift{\pgfpoint{0 bp } { 0 bp }  }  \pgftransformrotate{0 }  \pgftransformscale{2.64 }  }}}
\pgfdeclarehorizontalshading{_y5uoy9rpz}{150bp}{rgb(0bp)=(0.99,0.97,0.93);
rgb(54.285714285714285bp)=(0.99,0.97,0.93);
rgb(61.96428571428571bp)=(0.98,0.95,0.95);
rgb(100bp)=(0.98,0.95,0.95)}
\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1.3,xscale=1.3]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Shape: Polygon Curved [id:ds24835565753561872] 
\draw  [draw opacity=0.05][shading=_y5uoy9rpz,_3eubqr20l] (228.87,88.88) .. controls (266.87,64.88) and (266.87,111.88) .. (282.87,123.88) .. controls (298.87,135.88) and (360.87,96.88) .. (335.87,141.88) .. controls (310.87,186.88) and (389.87,249.88) .. (305.87,226.88) .. controls (221.87,203.88) and (251.87,247.88) .. (208.87,236.88) .. controls (165.87,225.88) and (201.87,193.88) .. (183.87,172.88) .. controls (165.87,151.88) and (157.87,118.88) .. (191.87,123.88) .. controls (225.87,128.88) and (190.87,112.88) .. (228.87,88.88) -- cycle ;
%Shape: Circle [id:dp2977666721327956] 
\draw  [draw opacity=0][fill={rgb, 255:red, 253; green, 170; blue, 30 }, fill opacity=0.70 ][general shadow={fill={rgb, 255:red, 245; green, 166; blue, 35 },shadow xshift=0pt,shadow yshift=0pt, opacity=0 }] (242,165.5) .. controls (248,147) and (253,132) .. (271.5,132) .. controls (290,132) and (305,147) .. (308,165.5) .. controls (310,184) and (290,199) .. (271.5,199) .. controls (253,199) and (238,184) .. (242,165.5) -- cycle ;
%Shape: Circle [id:dp2977666721327956] 
\draw  [draw opacity=0.05, scale=0.8,xshift=51pt,yshift=31pt][fill={rgb, 255:red, 253; green, 170; blue, 30 }, fill opacity=0.99 ][general shadow={fill={rgb, 255:red, 245; green, 166; blue, 35 },shadow xshift=0pt,shadow yshift=0pt, opacity=0 }] (242,165.5) .. controls (248,147) and (253,132) .. (271.5,132) .. controls (290,132) and (305,147) .. (308,165.5) .. controls (310,184) and (290,199) .. (271.5,199) .. controls (253,199) and (238,184) .. (242,165.5) -- cycle ;
%Shape: Ellipse [id:dp5805520465941827] 
%\draw  [draw opacity=0][fill={rgb, 255:red, 233; green, 152; blue, 19 }, fill opacity=1 ] (265.43,186.22) .. controls (261.59,181.1) and (265.3,171.81) .. (273.73,165.48) .. controls (282.16,159.14) and (292.12,158.15) .. (295.97,163.27) .. controls (299.81,168.39) and (296.1,177.67) .. (287.67,184.01) .. controls (279.23,190.35) and (269.28,191.34) .. (265.43,186.22) -- cycle ;
%Shape: Block Arc [id:dp4643699266244976] 
%\draw  [draw opacity=0.0][fill={rgb, 255:red, 255; green, 255; blue, 255 }, fill opacity=1 ] (181.64,151.16) .. controls (181.68,147.43) and (182.42,143.85) .. (183.93,140.65) .. controls (186.88,134.44) and (192.19,130.86) .. (198.43,130.09) -- (201.36,139.03) .. controls (196.68,139.19) and (192.72,141.5) .. (190.65,145.86) .. controls (189.57,148.15) and (189.12,150.76) .. (189.23,153.51) -- cycle ;
%Shape: Block Arc [id:dp28641962733560566] 
%\draw  [draw opacity=0.0][fill={rgb, 255:red, 255; green, 255; blue, 255 }, fill opacity=1 ] (209.55,189.06) .. controls (207.11,187.92) and (204.68,186.55) .. (202.32,184.94) .. controls (197.19,181.46) and (192.99,177.29) .. (189.87,172.88) -- (197.79,170.62) .. controls (200.18,173.44) and (203.18,176.15) .. (206.68,178.53) .. controls (208.26,179.61) and (209.87,180.57) .. (211.49,181.4) -- cycle ;
\node at (160,100) (nodedistribs) {$\distribs{\ab}$};
\node at (240,120) (nodeclass) {$\class_\ab$};
\node at (245,175) (nodeeps) {\scriptsize$\dst$};
\node at (275,165) (nodeproperty) {$\property_\ab$};
\end{tikzpicture}
\caption[An example of property to test. Here, $\property_\ab\subseteq \class_\ab\subseteq \distribs{\ab}$, where the property $\property_\ab$ is depicted as the inner orange area (``yolk''), and the ``egg white'' is the  area of rejection, \ie the subset of $\class_\ab$ at total variation distance at least $\dst$ from $\property_\ab$.]{An example of property to test. Here, $\property_\ab\subseteq \class_\ab\subseteq \distribs{\ab}$, where the property $\property_\ab$ is depicted as the inner orange area (``yolk''), and the ``egg white'' is the  area of rejection, \ie the subset of $\class_\ab$ at total variation distance at least $\dst$ from $\property_\ab$.\label{fig:propertytesting}\footnotemark}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Adapted from https://tex.stackexchange.com/questions/74168/how-can-i-draw-an-egg-using-tikz/598086#598086
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A few remarks are in order. First, in most of our applications we will take $\class_\ab=\distribs{\ab}$, so that the unknown distribution $\p$ is \emph{a priori} arbitrary, and the goal is to check whether it belongs to the subset (property) of interest $\property_\ab$. However, this need not always be the case, and we may want to choose $\class_\ab$ differently to perform hypothesis testing \emph{under structural assumptions}: for instance, to test whether an unknown unimodal distribution is actually Binomial (in this case, $\property_\ab \subsetneq \class_\ab\subsetneq \distribs{\ab}$), or if say a log-concave distribution is monotone (in which case there is no inclusion relation between $\property_\ab$ and $\class_\ab$, and both are strict subsets of $\distribs{\ab}$).

Another important point is that, while our main focus will be on \emph{discrete} distributions,~\cref{def:testing} allows for continuous distributions as well. Finally, the above definition is quite flexible, and can be seen to allow for testing \emph{multiple} distributions: for instance, taking $\domain_\ab=[\ab]\times[\ab]$, $\class_\ab \eqdef \setOfSuchThat{ \p\in\distribs{\ab} }{ \p=\p_1\otimes\p_2 }$ (product distributions), and $\property_\ab \eqdef \setOfSuchThat{\p_1\otimes\p_2 \in \class_\ab}{\p_1=\p_2}$, we obtain the question of two-sample testing (a.k.a.\ closeness testing), which asks to test whether two unknown distributions over $[\ab]$ are equal, or far from each other.
%%%%%%%%%%%%
\footnotetext{TikZ code for \cref{fig:propertytesting} adapted from~\url{https://tex.stackexchange.com/a/598086/31516}.}
%%%%%%%%%%%%
\paragraph{Dependence on the error probability $\errprob$.} Our definition of testing algorithm leaves the error probability $\errprob$ as a free parameter; however, it is quite common in the distribution testing literature to set it as some arbitrary constant smaller than $1/2$ (usually $1/3$). Indeed, by a standard argument,\index{probability amplification} an error probability $1/3$ can be driven down to arbitrary $\errprob$ at the price of a $\bigO{\log(1/\errprob)}$ factor in the sample complexity. 
\begin{lemma}[Error probability amplification]
  \label{lemma:error:proba:amplification}
  Fix $\property$ and $\class$, and suppose there exists a testing algorithm $\Algo$ for $\property$ under $\class$ with sample complexity $\ns(\ab,\dst,1/3)$ and time complexity $\tc(\ab,\dst,1/3)$. Then there is a testing algorithm $\Algo'$ for $\property$ under $\class$ with sample and time complexities $\ns'(\ab,\dst,\errprob) \eqdef \ns(\ab,\dst,1/3)\clg{18\ln(1/\errprob)}$ and $\tc'(\ab,\dst,\errprob) \eqdef \bigO{ \tc(\ab,\dst,1/3) \log(1/\errprob)}$.\cmargin{Logarithm is binary!}
\end{lemma}
\begin{proof}[Proof sketch]
Fix $\property$, $\class$, $\Algo$ as in the statement. Given $\ab,\dst$, and $\errprob\in(0,1]$, let $\Algo'$ be the algorithm which takes as input a multiset of $\ns'(\ab,\dst,\errprob)$ elements, partitions it (arbitrarily) in $m \eqdef \clg{18\ln(1/\errprob)}$ disjoint multisets $S_1,\dots, S_m$, runs $\Algo$ independently on those $m$ multisets with error probability $1/3$ to get $\mathbf{b}_1,\dots,\mathbf{b}_m$, and finally outputs the majority answer $\mathbf{b} \eqdef \indic{\sum_{i=1}^m \mathbf{b}_i \geq m/2}$. The running time is dominated by the $m$ executions, giving the claimed $\bigO{m\cdot \tc(\ab,\dst,1/3)}$ bound. Thus, it suffices to check that the output is correct with probability at least $1-\errprob$; this in turn follows from a Hoeffding bound (\cref{theo:hoeffding}). Indeed, by assumption, each $\mathbf{b}_i$ is independently correct with some probability $p\geq 2/3$. Letting $X_i \sim \bernoulli{p}$ be the indicator of the event ``{$\mathbf{b}_i$ is the correct output},'' we have
\[
  \probaOf{\mathbf{b} \text{ incorrect}} = \probaOf{ \frac{1}{m}\sum_{i=1}^m X_i  < \frac{1}{2} } \leq e^{-2(p-1/2)^2m} \leq e^{-m/18} \leq \errprob\,,
\]
where we used our setting of $m$ in the last inequality. 
\end{proof}
Importantly, this logarithmic dependence is not always the right one: as we will see in~\cref{chap:identity}, there exist natural problems for which the right dependence on the error probability only scales as $\sqrt{\log(1/\errprob)}$.

\paragraph{The learning baseline.}
Before setting out to design specific algorithms for various testing tasks and analyze their performance, it is good to have some sort of baseline to compare the result to. The most natural one is the \emph{testing-by-learning} approach, which can essentially be summarized as follows: the sample complexity of testing $\property= \bigcup_{\ab=1}^\infty \property_\ab$ under $\class= \bigcup_{\ab=1}^\infty \class_\ab$ is at most the sample complexity of, given $\ab$, \emph{learning} an arbitrary distribution from $\property_\ab\cup\class_\ab$. More specifically, we have the following:
\begin{lemma}[Testing by Learning]
	\label{lemma:learning:baseline}
  Fix any $\property= \bigcup_{\ab=1}^\infty \property_\ab$ and $\class= \bigcup_{\ab=1}^\infty \class_\ab$, and let $\ns_{\mathcal{L}}(\ab,\dst,\errprob)$ denote the sample complexity of learning an arbitrary probability distribution from $\property_\ab\cup\class_\ab\subseteq \distribs{\ab}$ to total variation $\dst$ with error probability at most $\errprob$. Then, the sample complexity $\ns$ of testing \property under $\class$ satisfies
  \[
      \ns(\ab,\dst,\errprob) \leq \ns_{\mathcal{L}}(\ab,\tfrac{\dst}{2},\errprob)\,.
  \]
  This is not necessarily achieved by a computationally efficient tester.
\end{lemma}
\begin{proof}
Fix a learning algorithm $\Algo$ for $\property_\ab\cup\class_\ab$ with sample complexity $\ns\eqdef \ns_{\mathcal{L}}(\ab,\tfrac{\dst}{2},\errprob)$. By running it on $\ns$ \iid samples from $\p$ (which we are promised either belongs to $\property_\ab$ or $\class_\ab$), we obtain a distribution $\hat{\p}$ such that $\totalvardist{\hat{\p}}{\p} \leq \dst/2$ with probability at least $1-\delta$. Assuming this is the case, then (i)~if $\p\in\property_\ab$, then of course $\totalvardist{\hat{\p}}{\property} \leq \dst/2$; while (ii)~if $\totalvardist{\p}{\property} > \dst$, by the triangle inequality (since total variation distance is a metric) we must have $\totalvardist{\hat{\p}}{\property} > \dst/2$. 

But we have an explicit description of $\hat{\p}$ in our hands, so we can check which of the two cases holds -- this may not be computationally efficient, but does not require any additional sample from $\p$. Thus, we have a \emph{bona fide} testing algorithm for \property under $\class$.
\end{proof}
Importantly, this baseline is with respect to the sample complexity of learning distributions from $\property_\ab\cup\class_\ab$, \emph{not} just $\property_\ab$: the latter is in general much larger! For instance, if $\property_\ab$ is a singleton but $\class_\ab=\distribs{\ab}$ (\eg as in identity testing, which we shall see in~\cref{chap:identity}) then learning $\property_\ab$ has sample complexity $0$, but learning $\property_\ab\cup\class_\ab=\distribs{\ab}$ has sample complexity $\Omega(\ab)$. This leads us to our baseline: since $\property_\ab\cup\class_\ab\subseteq \distribs{\ab}$, the sample complexity of \emph{any} distribution testing problem is at most the sample complexity of learning an arbitrary distribution over a known domain of the same size, which we record below:
\begin{theorem}[Learning baseline]
  \label{theo:learningbaseline}
  The sample complexity of learning an arbitrary probability distribution from $\distribs{\ab}$ to total variation $\dst$ with error probability at most $\errprob$ is
  \[
      \ns_{\mathcal{L}}(\ab,\dst,\errprob) = \bigTheta{\frac{\ab+\log(1/\errprob)}{\dst^2}}\,,
  \]
  giving an upper bound on the sample complexity of any testing problem.
\end{theorem}
The proof can be found in various places; \eg~\citet{KOPS:15,Canonne20:learning:short}. This testing-by-learning baseline, which is linear in the domain size $\ab$, motivates the name commonly given to testing algorithms which achieve significantly better sample complexity: \emph{sublinear algorithms}.

\paragraph{Worst-case distance parameter $\dst$.} \label{chap:what:adaptive}
As defined, a testing algorithm must reject all distributions which are at distance greater than $\dst$ from the property, where $\dst$ is provided as an input parameter. In particular, the requirement is oblivious to the \emph{true} distance $\dst(\p) \eqdef \totalvardist{\p}{\property_\ab} > \dst$ of the unknown distribution $\p$ to the property, and the sample complexity is just expressed as a function of the ``worst-case'' $\dst$. Instead of this, one may want an \emph{adaptive} algorithm which only takes the number of samples ``needed'' to reject, as a function of $\dst(\p)$: after all, in cases where $\dst(\p) \gg \dst$, one may reject after taking much fewer samples.

As it turns out, our focus on ``worst-case $\dst$'' readily implies this adaptive setting, via the use of a \emph{doubling search}. The idea is quite simple: given a testing algorithm $\Algo$, we create an adaptive testing algorithm $\Algo'$ by repeatedly trying to guess the true distance $\dst(\p)$, starting at $\dst_0=1$ and halving our current guess $\dst_j$ at every stage until we reach $\dst_L = \dst$, and calling $\Algo$ for every guess, with parameters $\ab$, $\dst_j$, and a suitable probability of failure $\errprob_j$ at stage $j$. If any of these (at most $L\eqdef \clg{\log(1/\dst)}$) calls leads to a rejection, $\Algo'$ outputs \reject; otherwise, it outputs $\accept$. The key is to choose $\errprob_j$ suitably so that (1) by a union bound all invocations of $\Algo$ are correct with probability at least $1-\errprob$, but (2)~the union bound does not cost too much in terms of sample complexity. A standard way to do so is to set $\errprob_j \eqdef \frac{\errprob}{2(j+1)^2}$ (though many other choices of convergent series would do), so that $\sum_{j=0}^\infty \errprob_j \leq \errprob$.

The resulting sample complexity will then be, in the case $\dst(\p) > \dst$,
\[
    \sum_{j=0}^{\clg{\log(1/\dst(\p))}} \ns(\ab, \dst_j, \errprob_j)
    = \sum_{j=0}^{\clg{\log(1/\dst(\p))}} \ns\Paren{\ab, 2^{-j}, \frac{\errprob}{2(j+1)^2}}\,,
\]
where $\ns(\cdot,\cdot,\cdot)$ denotes the sample complexity of $\Algo$. Under very mild conditions on $\ns$, this will be of the order $\ns\Paren{\ab, \dst(\p), \frac{\errprob}{\log(1/\dst(\p))}}$, and recalling that the dependence on the error probability is at worst logarithmic, this means that adapting to the true value of $\dst(\p)$ incurs a cost at most doubly logarithmic in $\dst(\p)$. Of course, when $\p\in\property_\ab$, our adaptive algorithm $\Algo'$ should run for all of the $L\eqdef \clg{\log(1/\dst)}$ iterations (until $\dst_L$) in order to output $\accept$, in which case the sample complexity will be bounded as
\[
    \sum_{j=0}^{\clg{\log(1/\dst)}} \ns\Paren{\ab, 2^{-j}, \frac{\errprob}{2(j+1)^2}}\,.
\]
We will see a concrete example of this technique in~\cref{ex:unif:adaptive}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Why total variation distance?}

The standard formulation of distribution testing, as stated in~\cref{def:testing}, is tied to a specific metric between probability distributions: the total variation distance (\cref{def:tv}). It is natural to wonder if that choice is arbitrary, and, if not, what motivates it.
\begin{itemize}
  \item Total variation distance provides a \emph{very strong guarantee}, and for instance is the most stringent of all $\lp[p]$ norms. This has practical consequences: if a source of data passes the test, then it will be nearly ``as good as if it had the desired property'' as far as \emph{any} algorithm is concerned. 
  \item It is \emph{well-behaved}: total variation distance defines a proper metric, and thus satisfies for instance the triangle inequality (which cannot be said about, for instance, Kullback--Leibler divergence). It is also nicely bounded, and will not take infinite values due to pathological reasons.
  \item It satisfies the \emph{data processing inequality} (\cref{fact:dpi}), which means it is robust to preprocessing. If data comes from two sources close in total variation distance, then post-processing this data cannot make their distribution statistically further apart. This is not the case for, among others, the $\lp[2]$ metric.
  \item Its relation to hypothesis testing: total variation distance has a natural and precise interpretation in terms of \emph{distinguishability}. This is formalized in~\cref{lemma:pearsonneyman}, and makes total variation distance the ``right'' notion of distance in applications such as cryptography, and when arguing about indistinguishability of data sources.
  \item Its connection to other distance measures. Total variation distance enjoys various inequalities relating it to other distance measures such as Kullback--Leibler divergence, $\lp[p]$ metrics, Hellinger distance, Kolmogorov distance, and Wasserstein (Earthmover) metric. Some of those are elaborated upon in~\cref{app:distances}.
\end{itemize}

Of course, total variation distance also has its drawbacks: it is sometimes too stringent, especially when considering distributions over continuous domains: in that case, absent further assumptions on the unknown continuous density, the testing problem becomes trivially impossible~\citep{LeCam73}. It also does not ``tensorize'' well (as opposed to, say, Hellinger distance or Kullback--Leibler divergence), meaning that the total variation distance between product measures does not have a nice form with respect to the total variation distances between individual marginals. And indeed, there are pros and cons to each choice; although in this case the above should convince you that the pros vastly outnumber the cons.

\paragraph{Relation to hypothesis testing.} As aforementioned, there is a natural connection between total variation distance and hypothesis testing, which we recall below. 
\begin{lemma}[Pearson--Neyman]
  \label{lemma:pearsonneyman}
  Any (possibly randomized) statistical test which distinguishes between $\p_0$ and $\p_1$ from a single sample must have Type~I (false positive) and Type-II (false negative) errors satisfying
  \[
      \text{Type~I} + \text{Type~II} \geq 1- \totalvardist{\p_0}{\p_1}
  \]
  Moreover, this is achieved by the test which outputs $1$ if, and only if, the sample belongs to the set $S^\ast \eqdef \setOfSuchThat{x}{\p_1(x) > \p_0(x)}$.
\end{lemma}
\begin{proof}
Fix any test $\Algo$ distinguishing between two distributions $\p_0$ and $\p_1$, given a single observation. Letting $\alpha$ and $\beta$ denote the Type~I and Type-II errors of $\Algo$, we have
\begin{align*}
  \alpha+\beta 
  &= \probaDistrOf{\p_0,R}{\Algo(X,R)=1} + \probaDistrOf{\p_1,R}{\Algo(X,R)=0} \\
  &= \shortexpect_{R}[ \probaDistrOf{\p_0}{\Algo(X,R)=1} ] + \shortexpect_{R}[ \probaDistrOf{\p_1}{\Algo(X,R)=0} ] \\
  &= \shortexpect_{R}[ \probaDistrOf{\p_0}{\Algo(X,R)=1} + \probaDistrOf{\p_1}{\Algo(X,R)=0} ]
%   \totalvardist{\p}{\q}
\end{align*}
where we denote by $R$ the internal randomness of $\Algo$. Since, for any fixed realization $r$ of this randomness $R$, the resulting test $\Algo(\cdot,r)$ is deterministic, we can define for any $r$ the \emph{acceptance region} $S_{\Algo,r} \eqdef \setOfSuchThat{x}{\Algo(x,r)=1}$, and write
\begin{align*}
  \alpha+\beta 
  &= \shortexpect_{R}[ \probaDistrOf{\p_0}{X \in S_{\Algo,R}} + \probaDistrOf{\p_1}{X \notin S_{\Algo,R}} ] \\
  &= 1+\shortexpect_{R}[ \p_0(S_{\Algo,R}) - \p_1(S_{\Algo,R}) ] \\
  &\geq 1 + \inf_{S}(\p_0(S) - \p_1(S)) \\
  &= 1 - \sup_{S}(\p_1(S) - \p_0(S)) \\
  &= 1- \totalvardist{\p_0}{\p_1}\,,
\end{align*}
as claimed. Finally, it is immediate from the definition of total variation distance that the proposed test satisfies $\text{Type~I} + \text{Type~II} = 1 + \p_0(S^\ast) - \p_1(S^\ast) = 1- \totalvardist{\p_0}{\p_1}$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The road not taken: tolerant testing}
In~\cref{def:testing} and throughout this survey, we focus on the standard formulation version of testing, where the unknown distribution $\p$ either \emph{belongs} to the property $\cP_\ab$ or is far from it. A natural generalization of this, allowing for some ``tolerance'' to noise or misspecification in the former case, would be to ask to distinguish $\p$ \emph{close} to $\cP_\ab$ from $\p$ far from it. This is called \emph{tolerant testing}~\cite{ParnasRR06}, and is formalized by introducing two parameters $0\leq \dst' < \dst \leq 1$, and relaxing the first item of~\cref{def:testing} to 
\begin{quote}
If $S$ is \iid from some $\p\in\distribs{\ab}$ such that $\totalvardist{\p}{\property_\ab} \leq \dst'$, then $\probaDistrOf{S,\Algo}{\mathbf{b}=\accept} \geq 1-\errprob$;
\end{quote}
(Note then that our regular, ``non-tolerant'' testing corresponds to taking $\dst'=0$.) The tolerant testing task, sometimes called in Statistics testing with an \emph{imprecise null}, typically requires a much higher sample complexity than the non-tolerant one~\citep{VV:11:stoc}, and both algorithms and lower bounds are obtained via significantly different techniques. For this reason, we will not here discuss tolerant testing in much, or indeed any detail: the interested reader is referred to, \eg~\citet{WuY20} for a primer on some of those techniques, and to~\citet{CanonneJKL21} and references within for an overview of results on tolerant goodness-of-fit testing.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Historical notes}
Hypothesis testing has a long and rich history in Statistics, starting with the work of~\citet{Pearson1900} introducing the $\chi^2$ test, and leading to substantial advances over the next century. While it is difficult and slightly dangerous to reduce twelve decades of intense research and study in a few sentences,\footnote{Which is exactly what the following paragraph will set out to do regardless.} standard approaches in Statistics share a few common features. First, they are \emph{asymptotic} in nature (as opposite to focusing on finite-sample guarantees), establishing and studying the limiting distribution of a given test as the sample size goes to infinity. This enables one to compute confidence intervals, and obtain a swath of information from the limiting distribution; but by itself provides little insight regarding the intermediate, finite-sample regime. Second, they tend to focus on the so-called Type~I error (significance of the test), \ie the probability to mistakenly reject the null hypothesis $\mathcal{H}_0$, and only after fixing this significance level set out to minimize the Type~II error (that is, maximize the \emph{power} of the test), which is the probability to mistakenly accept the alternative hypothesis $\mathcal{H}_1$. This is, again, an oversimplification; the reader should refer to, \eg~\citet{BalakrishnanW18} for a complementary and more detailed view. Nonetheless, these features are two of the most salient points of contrast with the very recent and related take on hypothesis testing from the theoretical computer science community, \emph{distribution testing}, which perhaps shares most similarity with the work of Ingster~\citep{Ingster86,Ingster97}.

Distribution testing was first introduced in an influential paper by~\citet{GoldreichGR98}, which formally defined the broader field of property testing; \citet{GoldreichR00} then specifically considered the question of testing uniformity of an unknown probability distribution (in an~$\lp[2]$ sense), using the collision-based tester to test whether a random walk had (approximately) reached its stationary distribution.

This was, however, only implicitly using uniformity testing as a subroutine in the context of testing some property (expansion) of bounded-degree graphs. The work of \citet{BatuFRSW00} first considers distribution testing for its own sake, studying the question of \emph{closeness testing} (\ie two-sample testing), where one seeks to decide from samples if two unknown distributions are equal. This initiated a long line of work on testing many properties~--~including uniformity, identity, closeness, monotonicity, independence (being a product distribution), to name only a few.

While the early papers focused on the dependence on the domain size $\ab$, treating the distance parameter $\dst$ as a small constant or a second-order concern, later works, beginning with~\citet{ChanDVV14}, started looking for the tight dependence on $\dst$ as well. Even more recently, the ``right'' dependence on $\errprob$, the error probability, has come into focus as well~\citep{DiakonikolasGPP18,DiakonikolasGKP21}. This, in some sense, brings the theoretical computer science closer to the information theory literature, where the focus on the \emph{error exponent} (that is, the rate at which the error probability decays exponentially, as a function of the other parameters) is the standard view.\cmargin{[citation needed]}

Another recent trend in distribution testing has been to consider different ``accesses'' to the data, rather than \iid samples: for instance, access to so-called conditional samples~\citep{CRS:15,CFGM:13}, or the ability to ask for, or observe, the probability of individual elements of the domain~\citep{RubinfeldS09,CanonneR14,OnakS18}. These types of access allow for much more efficient testing algorithms, but require significantly different algorithmic tools and proof techniques, and we will not discuss them here. For more on this, we defer the interested reader to another survey,~\citet{Canonne:15:Survey}.

Finally, over the past few years distribution testing has ventured into adjacent areas of computer science and information theory, by incorporating various constraints and resources into its formulation. Examples include data privacy (and, more specifically, \emph{differential privacy}~\citep{DworkMNS06} and its variants)~--~see, \eg \citep{KamathU20}, memory constraints, and bandwidth constraints~\citep{Tsitsiklis:93}; of which we will cover a fraction in~\cref{chap:constrained}. This has been done by borrowing, extending, and (re)discovering ideas and techniques from these areas and Statistics; somewhat satisfyingly, leading distribution testing back to some of its roots. 

This survey aims to describe some of these connections, and provide an overview of these ideas and techniques which took years for the author to learn about.
